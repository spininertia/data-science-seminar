Probabilistic latent semantic indexing\cite{hofmann1999probabilistic} is an extension to LSI which puts topic modeling under a probability framework, with which we can fit the model by maximum likelihood or Bayesian method.

Its main idea is that each word of a document is sampled from a \emph{mixture model}, where a component is a \emph{topic} which has its own distribution with respect to the words. PLSA is also a generative model, we sample a topic variable for in each position, then the actual word is generated from the specific topic's distribution over words. 

\subsection{Learning}
Intro EM method.

\subsection{Inferencing}
The difficulty with inference. 

\subsection{Problem}